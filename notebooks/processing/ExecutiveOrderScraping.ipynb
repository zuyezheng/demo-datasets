{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3c68750a3bcbec",
   "metadata": {},
   "source": [
    "# Executive Order Scraping\n",
    "\n",
    "Pulling from https://www.presidency.ucsb.edu/documents/app-categories/written-presidential-orders/presidential/executive-orders which seems more complete than https://www.federalregister.gov/documents/search with older EOs as text instead of source document scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f4f8735107f93dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T01:02:55.201585Z",
     "start_time": "2025-02-27T01:02:54.998772Z"
    }
   },
   "outputs": [],
   "source": [
    "%run notebooks/Setup.ipynb\n",
    "\n",
    "import requests\n",
    "import pandas\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb36e798185cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T23:21:33.534151Z",
     "start_time": "2025-02-26T23:21:33.530745Z"
    }
   },
   "outputs": [],
   "source": [
    "host = \"https://www.presidency.ucsb.edu\"\n",
    "\n",
    "def get_executive_order_links(url: str):\n",
    "    \"\"\"\n",
    "    Fetch the main page of executive orders and extract links to individual orders.\n",
    "    Returns a list of relative links (since the site uses relative paths).\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # find the div with class \"view-content\" which contains the list of executive orders\n",
    "    view_content_div = soup.find(\"div\", class_=\"view-content\")\n",
    "\n",
    "    if not view_content_div:\n",
    "        return None\n",
    "\n",
    "    # iterate through all the divs with class \"field-title\"\n",
    "    eo_links = []\n",
    "    for field_title_div in view_content_div.find_all(\"div\", class_=\"field-title\"):\n",
    "        anchor_tag = field_title_div.find(\"a\")\n",
    "        if anchor_tag:\n",
    "            eo_links.append(anchor_tag[\"href\"])\n",
    "\n",
    "    return eo_links\n",
    "\n",
    "def get_eo_links(num_pages: int):\n",
    "    \"\"\"\n",
    "    Fetch the main page of executive orders and extract links to individual orders.\n",
    "    Returns a list of relative links (since the site uses relative paths).\n",
    "    \"\"\"\n",
    "    base_url = host + \"/documents/app-categories/written-presidential-orders/presidential/executive-orders?items_per_page=100\"\n",
    "    eo_links = []\n",
    "    for i in range(num_pages):\n",
    "        url = f\"{base_url}?page={i}\"\n",
    "        page_links = get_executive_order_links(url)\n",
    "        if page_links:\n",
    "            eo_links.extend(page_links)\n",
    "            \n",
    "    return eo_links\n",
    "\n",
    "def get_executive_order(url: str):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    def clean_text(text):\n",
    "        return text.replace(\"\\xa0\", \" \").replace(\"\\u2014\", \"-\").strip()\n",
    "\n",
    "    # fetch person details\n",
    "    person_div = soup.find(\"div\", class_=\"field-docs-person\")\n",
    "    person_title = clean_text(person_div.find(\"div\", class_=\"field-title\").text)\n",
    "    person_byline = clean_text(person_div.find(\"div\", class_=\"field-ds-byline\").text)\n",
    "    eo_title = clean_text(person_div.find(\"div\", class_=\"field-ds-doc-title\").text)\n",
    "\n",
    "    # fetch the date\n",
    "    date_div = clean_text(soup.find(\"div\", class_=\"field-docs-start-date-time\").text)\n",
    "\n",
    "    # read the content and collect each paragraph as an array of strings\n",
    "    content_div = soup.find(\"div\", class_=\"field-docs-content\")\n",
    "    content = [clean_text(paragraph.text) for paragraph in content_div.find_all(\"p\")]\n",
    "\n",
    "    citation = clean_text(soup.find(\"div\", class_=\"field-prez-document-citation\").text)\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"doc\": url.split(\"/\")[-1],\n",
    "        \"president\": person_title,\n",
    "        \"president_byline\": person_byline,\n",
    "        \"title\": eo_title,\n",
    "        \"date\": date_div,\n",
    "        \"content\": content,\n",
    "        \"citation\": citation\n",
    "    }\n",
    "\n",
    "def save_executive_orders(eos_to_fetch: list[str], skip_existing: bool = True):\n",
    "    # fetch each executive order and write to a json file\n",
    "    for eos_link in eos_to_fetch:\n",
    "        eo_path = Path(\"data/executive_orders/raw\").joinpath(eos_link.split(\"/\")[-1])\n",
    "        # see if we need to skip\n",
    "        if skip_existing and eo_path.exists():\n",
    "            print(f\"Skipping {eos_link}\")\n",
    "            continue\n",
    "\n",
    "        eo = get_executive_order(host + eos_link)\n",
    "        if eo:\n",
    "            with open(eo_path, \"w\") as f:\n",
    "                json.dump(eo, f, indent=4)\n",
    "\n",
    "                print(f\"Fetched {eos_link}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch {eos_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8cf4136a11f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T05:34:57.123082Z",
     "start_time": "2025-02-27T05:34:57.112693Z"
    }
   },
   "outputs": [],
   "source": [
    "# initial pull of all links\n",
    "all_eo_links = get_eo_links(200)\n",
    "\n",
    "# write the links to a csv file\n",
    "pandas.DataFrame(all_eo_links, columns=[\"link\"]) \\\n",
    "    .to_csv(\"data/executive_orders/links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07709da9f3b8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial fetch of all eos\n",
    "eos_to_fetch = pandas.read_csv(\"data/executive_orders/links.csv\")[\"link\"].tolist()\n",
    "save_executive_orders(eos_to_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a835b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/documents/executive-order-14213-establishing-the-national-energy-dominance-council',\n",
       " '/documents/executive-order-implementing-the-presidents-department-government-efficiency-cost']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update with recent eos\n",
    "new_eo_links = get_eo_links(2)\n",
    "\n",
    "# diff the new eos with those saved\n",
    "prior_eos = pandas.read_csv(\"data/executive_orders/links.csv\")[\"link\"].tolist()\n",
    "new_eos = list(set(new_eo_links) - set(prior_eos))\n",
    "\n",
    "# merge the new eos to the top of the links and save\n",
    "all_eo_links = new_eos + prior_eos\n",
    "pandas.DataFrame(all_eo_links, columns=[\"link\"]) \\\n",
    "    .to_csv(\"data/executive_orders/links.csv\", index=False)\n",
    "\n",
    "new_eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67691b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /documents/executive-order-14213-establishing-the-national-energy-dominance-council\n",
      "Fetched /documents/executive-order-14213-establishing-the-national-energy-dominance-council\n",
      "Skipping /documents/executive-order-implementing-the-presidents-department-government-efficiency-cost\n",
      "Fetched /documents/executive-order-implementing-the-presidents-department-government-efficiency-cost\n"
     ]
    }
   ],
   "source": [
    "save_executive_orders(new_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1df595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
