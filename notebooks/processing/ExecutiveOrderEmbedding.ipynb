{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Order Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/Setup.ipynb\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import pandas\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import queue\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu\n",
    "\"\"\"\n",
    "models = [\n",
    "    [0, SentenceTransformer(\"Salesforce/SFR-Embedding-2_R\")]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# gpu\n",
    "num_gpus = 1\n",
    "models = [\n",
    "    [i, SentenceTransformer(\"Salesforce/SFR-Embedding-2_R\", device=f'cuda:{i}')] for i in range(num_gpus)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed EOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batches of EOs to embed\n",
    "eo_dir = 'data/executive_orders/raw/'\n",
    "eo_paths = os.listdir(eo_dir)\n",
    "\n",
    "def batched(list_in, batch_size):\n",
    "    return [list_in[i * batch_size:(i + 1) * batch_size] for i in range((len(list_in) + batch_size - 1) // batch_size )]\n",
    "\n",
    "eo_paths_batches = batched(eo_paths, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to embed\n",
    "if not os.path.exists('data/executive_orders/embeddings'):\n",
    "    os.makedirs('data/executive_orders/embeddings')\n",
    "\n",
    "def embed_batch(batch_i, batch, model):\n",
    "    eos = []\n",
    "    for path in batch:\n",
    "        with open(eo_dir + path, 'r') as f:\n",
    "            eo_doc = json.load(f)\n",
    "        eos.append('\\n'.join(eo_doc['content']))\n",
    "\n",
    "    embeddings = model.encode(list(map(lambda x: str(x), eos)))\n",
    "\n",
    "    df = pandas.DataFrame(embeddings)\n",
    "    df.insert(0, 'file', batch)\n",
    "    df.to_csv(f'data/executive_orders/embeddings/batch_{batch_i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the emdeddings\n",
    "model_pool = queue.Queue()\n",
    "for model in models:\n",
    "    model_pool.put(model)\n",
    "\n",
    "def process_batch(i, batch):\n",
    "    # block until a model becomes available\n",
    "    model = model_pool.get()\n",
    "    try:\n",
    "        embed_batch(i, batch, model[1])\n",
    "        print(f\"Embedded batch {i} with model {model[0]}\")\n",
    "    finally:\n",
    "        model_pool.put(model)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(models)) as executor:\n",
    "    for i, batch in enumerate(eo_paths_batches):\n",
    "        executor.submit(process_batch, i, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = 'data/executive_orders/embeddings/'\n",
    "embeddings_paths = os.listdir(embeddings_dir)\n",
    "\n",
    "def load_csv(file_name):\n",
    "    return pandas.read_csv(embeddings_dir + file_name, index_col=0)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings_dfs = list(executor.map(load_csv, embeddings_paths))\n",
    "\n",
    "embeddings_df = pandas.concat(embeddings_dfs, ignore_index=True)\n",
    "embeddings = embeddings_df.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "embeddings_df['cluster'] = clusters\n",
    "\n",
    "output_path = 'data/executive_orders/clusters.csv'\n",
    "embeddings_df[[\"file\", \"cluster\"]]\\\n",
    "    .sort_values(by=[\"cluster\", \"file\"])\\\n",
    "    .to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
