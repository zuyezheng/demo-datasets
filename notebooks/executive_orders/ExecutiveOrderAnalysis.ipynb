{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Order Analysis\n",
    "\n",
    "Use the clusters to analyze executive orders to build tags and cluster titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = 'data/executive_orders/cluster_analysis/'\n",
    "\n",
    "clusters_df = pandas.read_csv('data/executive_orders/clusters.csv')\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.2,\n",
    "    max_retries=3,\n",
    "    max_output_tokens=8000\n",
    ")\n",
    "\n",
    "class SampleAnalysis(BaseModel):\n",
    "    analysis: str = Field(description='Analysis of the texts.')\n",
    "    tags: List[str] = Field(description='Tags assigned to the cluster..')\n",
    "    title: str = Field(description='Title of the cluster.')\n",
    "\n",
    "class SampleAnalysisWithCluster(SampleAnalysis):\n",
    "    cluster: int = Field(description='Cluster the analysis is for.')\n",
    "\n",
    "class RefinedAnalysis(BaseModel):\n",
    "    clusters: List[SampleAnalysisWithCluster] = Field(description='Refined analysis for each cluster in input order.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_markdown(sample):\n",
    "    return '\\n'.join([\n",
    "        f'## Analysis',\n",
    "        sample['analysis'],\n",
    "        f'## Tags',\n",
    "        ', '.join(sample['tags']),\n",
    "        f'## Title',\n",
    "        sample['title']\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "Sample documents within a cluster to analyze and start describing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tags_pipeline(model, n_texts: int):\n",
    "    \"\"\"\n",
    "    Pipeline to summarize a set of sample texts for a cluster.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        'Your task is to understand why the given documents were assigned to the same cluster of documents of the same type.',\n",
    "        '- First analyze the documents for common themes, topics, and sentiment.',\n",
    "        '- Then assign tags that would apply to all given documents and unique to this cluster based on your analysis.',\n",
    "        '- Finally give the cluster a title based on the analysis and derived tags to distinguish it from the other clusters.',\n",
    "        '- Do not use tags or titles that describe the document type, such as \"Executive Order\" or \"Presidential Orders\".',\n",
    "        '- Do not use generic phrases like \"Policies\", \"Regulations\", \"Orders\", or \"Actions\" in titles, be specific about what is in common in the documents.'\n",
    "    ]\n",
    "    for i in range(n_texts):\n",
    "        prompt.extend([\n",
    "            f'# Document {i+1}',\n",
    "            f'{{document_{i}}}',\n",
    "        ])\n",
    "\n",
    "    return ChatPromptTemplate.from_template(\n",
    "        '\\n'.join(prompt)\n",
    "    ) | model.with_structured_output(SampleAnalysis, include_raw=True)\n",
    "\n",
    "def sample_in_cluster(cluster: int, n_texts: int):\n",
    "    population = clusters_df[clusters_df['cluster'] == cluster]['path']\n",
    "    sampled = population.sample(min(n_texts, population.shape[0]))\n",
    "\n",
    "    documents = []\n",
    "    for p in sampled:\n",
    "        with open('data/executive_orders/raw/' + p) as f:\n",
    "            eo = json.load(f)\n",
    "            documents.append('\\n'.join(eo[\"content\"]))\n",
    "\n",
    "    return documents\n",
    "\n",
    "def sample_all_clusters(sample_size: int, sample_i: int):\n",
    "    results = [f'Sample size: {sample_size}']\n",
    "    for i in range(grouped.shape[0]):\n",
    "        sampled = sample_in_cluster(i, sample_size)\n",
    "        response = build_tags_pipeline(gemini, len(sampled))\\\n",
    "            .invoke({f'document_{d_i}': d for d_i, d in enumerate(sampled)})\n",
    "        \n",
    "        result = response['parsed'].model_dump() | {\n",
    "            'request': {\n",
    "                'cluster': i,\n",
    "                'sample_size': sample_size\n",
    "            },\n",
    "            'stats': {\n",
    "                'input_tokens': response['raw'].usage_metadata['input_tokens'],\n",
    "                'output_tokens': response['raw'].usage_metadata['output_tokens'],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(analysis_dir + f'{i}_{sample_size}_{sample_i}.json', 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "\n",
    "        results.append(f'{str(i)}: {response['parsed'].title}')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [10, 25, 50]\n",
    "base_samples = 2\n",
    "\n",
    "sample_params = []\n",
    "for sample_size in sample_sizes:\n",
    "    for i in range(base_samples * 50//sample_size):\n",
    "        sample_params.append((sample_size, i))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = [executor.submit(sample_all_clusters, *params) for params in sample_params]\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            print('\\n'.join(future.result()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Cluster Titles\n",
    "\n",
    "Go over all the samples and finalize a title for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for tag_file in [f for f in os.listdir(analysis_dir) if f.endswith('.json')]:\n",
    "    with open(analysis_dir + tag_file) as f:\n",
    "        sample = json.load(f)\n",
    "\n",
    "        samples.append({\n",
    "            'analysis': sample['analysis'],\n",
    "            'tags': sample['tags'],\n",
    "            'title': sample['title'],\n",
    "            'cluster': sample['request']['cluster'],\n",
    "            'sample_size': sample['request']['sample_size']\n",
    "        })\n",
    "\n",
    "samples_df = pandas.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coallate samples within each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cluster_pipeline(model, n_texts: int):\n",
    "    prompt = [\n",
    "        'Your task is build the final analysis, tags, and title for the document cluster given analysis across multiple samples of the cluster.',\n",
    "        '- Construct a meta-analysis of the differences and similarities in the analysis, tags, and titles from the invdividual samples.',\n",
    "        '- Based on the meta-analysis, refine the existing tags from the individual samples and coalesce them into a final set of tags.',\n",
    "        '- Based on the meta-analysis and revised tags, refine the existing titles from the individual samples and come up with a final title.',\n",
    "        '- Do not use generic phrases like \"Policies\", \"Executive Orders\", or \"Executive Actions\" in titles, be specific about what makes the cluster unique.'\n",
    "    ]\n",
    "    for i in range(n_texts):\n",
    "        prompt.extend([\n",
    "            f'# Sample {i+1}',\n",
    "            f'{{sample_{i}}}',\n",
    "        ])\n",
    "\n",
    "    return ChatPromptTemplate.from_template(\n",
    "        '\\n'.join(prompt)\n",
    "    ) | model.with_structured_output(SampleAnalysis, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29: Military and Veteran Personnel: Regulation Amendments and Management\n",
      "1: Amendments to Executive Orders: Government Structure and Personnel\n",
      "47: Executive Actions Modifying Government Regulations and Policies\n",
      "39: International Trade, Immigration, and Canal Regulations\n",
      "8: Presidential Directives on National and International Governance\n",
      "6: Executive Actions: Directing National Policy and Governance\n",
      "34: Customs Ports of Entry and Collection Districts: Modifications and Adjustments\n",
      "26: Governmental Actions on National Issues\n",
      "12: Adjustments to Existing Executive Orders and Delegations of Authority\n",
      "28: National Industrial Recovery Act (NIRA) Implementation and Industry Regulation\n",
      "27: Native American Land Reservations: Establishment, Modification, and Administration\n",
      "19: Presidential Exemptions to Mandatory Retirement for Government Employees\n",
      "10: Land Reservation and Withdrawal Management\n",
      "0: Military, Reconstruction, and Territorial Governance Directives, Civil War Era to Early 20th Century\n",
      "32: Executive Orders for Interagency Coordination and Policy Implementation\n",
      "20: Federal Land Withdrawal and Reservation for Public Purposes\n",
      "13: Federal Control of Resources and Production During Wartime\n",
      "16: Presidential Boards to Investigate Labor Disputes Threatening Interstate Commerce and National Safety\n",
      "18: Presidential Awards, Decorations, Seals, and Flags\n",
      "23: Truman Administration: Adjustments to Government Operations and Authority\n",
      "15: Presidential Orders of Succession within Federal Departments and Agencies\n",
      "11: Adjustments to Existing Executive Orders and Regulations\n",
      "30: Designations of International Organizations for Immunities and Privileges\n",
      "41: International Trade, Tariffs, and Export Regulations\n",
      "31: NIRA: Approvals, Modifications, and Exemptions of Fair Competition Codes\n",
      "43: Executive Branch Advisory Groups: Formation, Function, and Authority Delegation\n",
      "48: Executive Actions on National Security, Personnel, and International Relations\n",
      "44: Great Depression and New Deal Era: Federal Resource Management and Emergency Relief\n",
      "17: Land Management and Boundary Adjustments in US Territories and Military Reservations\n",
      "38: Extending Federal Trust on Native American Land Allotments, 1917-1950\n",
      "35: Civil Service: Rule Modifications, Exceptions, and Amendments\n",
      "36: Executive Branch Organization: Interagency Groups and Policy Directives\n",
      "37: Governmental Mourning and Remembrance\n",
      "46: U.S. Government Employee Compensation Adjustments\n",
      "33: Establishment and Management of Migratory Bird and Wildlife Refuges\n",
      "42: Presidential Advisory Committees, Commissions, and Councils\n",
      "14: California and Nevada Public Land Management: Withdrawals, Reservations, and Modifications (1867-1948)\n",
      "21: Civil Service Waivers for Bereaved Families and Former Government Employees\n",
      "7: Restricted Air and Sea Zones for National Defense and Public Safety\n",
      "49: Land Reopenings for Veterans Following Resurvey\n",
      "4: Government Land and Resource Management & Labor Regulation\n",
      "40: Executive Branch Organization: Authority, Coordination, and Policy Implementation\n",
      "5: Delegation of Presidential Authority to Government Officials and Agencies\n",
      "24: Land Withdrawal and Resurvey Orders in Western States\n",
      "3: Authorizing Government Access to Tax Return Information\n",
      "25: Land Management and Resource Allocation Adjustments in Arizona and New Mexico\n",
      "9: Presidential Exemptions to Mandatory Retirement for Government Employees, Act of June 30, 1932\n",
      "45: Civil Service - Examination, Appointment, and Eligibility Rule Changes\n",
      "22: Presidential Actions on National Security, Foreign Policy, and Governance\n",
      "2: Alaskan Land Reallocations and Reservations\n"
     ]
    }
   ],
   "source": [
    "coalesced_analysis = []\n",
    "for cluster in samples_df['cluster'].unique():\n",
    "    cluster_samples = samples_df[samples_df['cluster'] == cluster].reset_index(drop=True)\n",
    "\n",
    "    response = build_cluster_pipeline(gemini, cluster_samples.shape[0]).invoke({\n",
    "        f'sample_{i}': sample_to_markdown(sample) for i, sample in cluster_samples.iterrows()\n",
    "    })\n",
    "\n",
    "    coalesced = response['parsed'].model_dump() | {\n",
    "        'cluster': int(cluster),\n",
    "        'stats': {\n",
    "            'input_tokens': response['raw'].usage_metadata['input_tokens'],\n",
    "            'output_tokens': response['raw'].usage_metadata['output_tokens'],\n",
    "        }\n",
    "    }\n",
    "    print(f'{cluster}: {coalesced[\"title\"]}')\n",
    "\n",
    "    coalesced_analysis.append(coalesced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/executive_orders/coalesced_clusters.json', 'w') as f:\n",
    "    json.dump(coalesced_analysis, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine across clusters.\n",
    "\n",
    "With a single coallated analysis for each cluster, refine them by considering all of the other clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refine_pipeline(model, n_texts: int):\n",
    "    prompt = [\n",
    "        'Your task is to consider the coalesced analysis across all clusters of documents to refine into a final analysis.',\n",
    "        '- The given analysis only considers sampled document sets within each cluster, revise the analysis considering every other cluster to focus on what is unique.',\n",
    "        '- Considering the revised analysis and tags of all other clusters, refine the tags for each cluster.',\n",
    "        '- With the revised analysis and tags and considering all other clusters, refine the title to help characterize the current cluster and differentiate it from the rest.',\n",
    "        '- Do not use generic phrases like \"Policies\", \"Executive Orders\", or \"Executive Actions\" in titles, be specific about what makes the cluster unique.',\n",
    "    ]\n",
    "    for i in range(n_texts):\n",
    "        prompt.extend([\n",
    "            f'# Cluster {i}',\n",
    "            f'{{cluster_{i}}}',\n",
    "        ])\n",
    "\n",
    "    return ChatPromptTemplate.from_template(\n",
    "        '\\n'.join(prompt)\n",
    "    ) | model.with_structured_output(RefinedAnalysis, include_raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/executive_orders/coalesced_clusters.json') as f:\n",
    "    initial_coalesced = json.load(f)\n",
    "initial_coalesced.sort(key=lambda x: x['cluster'])\n",
    "\n",
    "refined_coalesced = build_refine_pipeline(gemini, len(initial_coalesced)).invoke({\n",
    "    f'cluster_{cluster['cluster']}': sample_to_markdown(cluster) for _, cluster in enumerate(initial_coalesced)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/executive_orders/refined_clusters.json', 'w') as f:\n",
    "    json.dump(list(map(lambda c: c.model_dump(), refined_coalesced['parsed'].clusters)), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
