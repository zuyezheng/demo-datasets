{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274b264ea4779321",
   "metadata": {},
   "source": [
    "# Executive Order Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a4b443aaa5c77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T00:46:36.923892Z",
     "start_time": "2025-03-06T00:46:36.921944Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import queue\n",
    "from typing import List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e232eef",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "Given how prevalent presidential names are in language, LLMs would have learned specific sentiments about them. To avoid names from biasing the embedding and sentiment analysis of executive orders, build a pipeline to make out names from the last few signature lines of each EO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(url):\n",
    "    return ChatOllama(\n",
    "        base_url=url,\n",
    "        model = \"qwen2.5\",\n",
    "        temperature = 0.0,\n",
    "        num_predict = 9000,\n",
    "        retries = 3\n",
    "    )\n",
    "\n",
    "model_pool = queue.Queue()\n",
    "model_pool.put(make_model(\"http://tr-pro.l.co:11434\"))\n",
    "model_pool.put(make_model(\"http://tr-pro.l.co:11435\"))\n",
    "model_pool.put(make_model(\"http://localhost:11434\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedResponse(BaseModel):\n",
    "    lines: List[str] = Field(description=\"Masked lines of input.\")\n",
    "\n",
    "def make_pipeline(model: BaseChatModel):\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        '\\n '.join([\n",
    "            'Mask all versions, full and abbreviated, of the name \"{name}\" with \"[NAME]\" from the inputs. For example: ',\n",
    "            '- [{name} THE WHITE HOUSE, September 30, 1993\"] should be masked as [\"[NAME] THE WHITE HOUSE, September 30, 1993\"]',\n",
    "            '- [\"{name}, Assistant-Adjutant General.\"] should be masked as [\"[NAME], Assistant-Adjutant General.\"]',\n",
    "            '- [\"{name}\", \"The White House,July 30, 1932.\"] should be masked as [\"[NAME]\", \"The White House,July 30, 1932.\"]',\n",
    "            '- [\"Approved:\", \"{name}.\"] should be masked as [\"Approved:\", \"[NAME].\"]',\n",
    "            '- [\"{name}.\"] should be masked as [\"[NAME].\"]',\n",
    "            'Ensure every input string has a corresponding string in the response.'\n",
    "            'Inputs: {input}',\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    return prompt | model.with_structured_output(MaskedResponse, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2b3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(result):\n",
    "    return {\n",
    "        'masked': result['parsed'].lines if result['parsed'] else None,\n",
    "        'model': result['raw'].response_metadata['model'],\n",
    "        'done': result['raw'].response_metadata['done'],\n",
    "        'total_duration': result['raw'].response_metadata['total_duration'],\n",
    "        'load_duration': result['raw'].response_metadata['load_duration'],\n",
    "        'prompt_eval_duration': result['raw'].response_metadata['prompt_eval_duration'],\n",
    "        'eval_duration': result['raw'].response_metadata['eval_duration'],\n",
    "        'input_tokens': result['raw'].usage_metadata['input_tokens'],\n",
    "        'output_tokens': result['raw'].usage_metadata['output_tokens']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked</th>\n",
       "      <th>model</th>\n",
       "      <th>done</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>load_duration</th>\n",
       "      <th>prompt_eval_duration</th>\n",
       "      <th>eval_duration</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sec. 4. This order shall take effect immediat...</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>939400561</td>\n",
       "      <td>33521893</td>\n",
       "      <td>138000000</td>\n",
       "      <td>749000000</td>\n",
       "      <td>382</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Sec. 4. This order shall take effect immediat...</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1644145153</td>\n",
       "      <td>41287426</td>\n",
       "      <td>43000000</td>\n",
       "      <td>660000000</td>\n",
       "      <td>384</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[NAME]\\nThe White House,\\nDecember 3, 1992.]</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>726999866</td>\n",
       "      <td>33183590</td>\n",
       "      <td>44000000</td>\n",
       "      <td>636000000</td>\n",
       "      <td>368</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[NAME], Assistant-Adjutant General.]</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1301686880</td>\n",
       "      <td>38818643</td>\n",
       "      <td>45000000</td>\n",
       "      <td>469000000</td>\n",
       "      <td>365</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Approved:, [NAME].]</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1152407238</td>\n",
       "      <td>38498454</td>\n",
       "      <td>29000000</td>\n",
       "      <td>395000000</td>\n",
       "      <td>360</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[NAME], The White House,, February 19, 2025.]</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>799421951</td>\n",
       "      <td>37118831</td>\n",
       "      <td>118000000</td>\n",
       "      <td>608000000</td>\n",
       "      <td>375</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[NAME], The White House,April 7, 1934.]</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>786130652</td>\n",
       "      <td>33777478</td>\n",
       "      <td>129000000</td>\n",
       "      <td>595000000</td>\n",
       "      <td>376</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[By the President, [NAME], [NAME][APP Note: Se...</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1392878128</td>\n",
       "      <td>40218654</td>\n",
       "      <td>33000000</td>\n",
       "      <td>559000000</td>\n",
       "      <td>370</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[NAME], The White House,July 30, 1932.]</td>\n",
       "      <td>qwen2.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1682791436</td>\n",
       "      <td>42005772</td>\n",
       "      <td>30000000</td>\n",
       "      <td>500000000</td>\n",
       "      <td>372</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              masked    model  done  \\\n",
       "0  [Sec. 4. This order shall take effect immediat...  qwen2.5  True   \n",
       "1  [Sec. 4. This order shall take effect immediat...  qwen2.5  True   \n",
       "2      [[NAME]\\nThe White House,\\nDecember 3, 1992.]  qwen2.5  True   \n",
       "3              [[NAME], Assistant-Adjutant General.]  qwen2.5  True   \n",
       "4                               [Approved:, [NAME].]  qwen2.5  True   \n",
       "5     [[NAME], The White House,, February 19, 2025.]  qwen2.5  True   \n",
       "6           [[NAME], The White House,April 7, 1934.]  qwen2.5  True   \n",
       "7  [By the President, [NAME], [NAME][APP Note: Se...  qwen2.5  True   \n",
       "8           [[NAME], The White House,July 30, 1932.]  qwen2.5  True   \n",
       "\n",
       "   total_duration  load_duration  prompt_eval_duration  eval_duration  \\\n",
       "0       939400561       33521893             138000000      749000000   \n",
       "1      1644145153       41287426              43000000      660000000   \n",
       "2       726999866       33183590              44000000      636000000   \n",
       "3      1301686880       38818643              45000000      469000000   \n",
       "4      1152407238       38498454              29000000      395000000   \n",
       "5       799421951       37118831             118000000      608000000   \n",
       "6       786130652       33777478             129000000      595000000   \n",
       "7      1392878128       40218654              33000000      559000000   \n",
       "8      1682791436       42005772              30000000      500000000   \n",
       "\n",
       "   input_tokens  output_tokens  \n",
       "0           382             50  \n",
       "1           384             50  \n",
       "2           368             38  \n",
       "3           365             31  \n",
       "4           360             26  \n",
       "5           375             41  \n",
       "6           376             40  \n",
       "7           370             38  \n",
       "8           372             40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try is out\n",
    "model = model_pool.get()\n",
    "masked = make_pipeline(model).batch([\n",
    "    {\n",
    "        'name': 'William J. Clinton',\n",
    "        'input': json.dumps([\n",
    "            \"Sec. 4. This order shall take effect immediately.\",\n",
    "            \"William J. ClintonTHE WHITE HOUSE,September 30, 1993.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'William J. Clinton',\n",
    "        'input': json.dumps([\n",
    "            \"Sec. 4. This order shall take effect immediately.\",\n",
    "            \"William Clinton\\nTHE WHITE HOUSE\\n,September 30, 1993.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'George Bush',\n",
    "        'input': json.dumps([\n",
    "            \"GEORGE BUSH\\nThe White House,\\nDecember 3, 1992.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ulysses S. Grant',\n",
    "        'input': json.dumps([\n",
    "            \"E. D. TOWNSEND, Assistant-Adjutant General.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ulysses S. Grant',\n",
    "        'input': json.dumps([\n",
    "            \"Approved:\",\n",
    "            \"U. S. Grant.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'Donald J. Trump',\n",
    "        'input': json.dumps([\n",
    "            \"DONALD J. TRUMP\",\n",
    "            \"The White House,\",\n",
    "            \"February 19, 2025.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'Franklin D. Roosevelt',\n",
    "        'input': json.dumps([\n",
    "            \"FDR\",\n",
    "            \"The White House,April 7, 1934.\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'George Washington',\n",
    "        'input': json.dumps([\n",
    "            \"By the President\",\n",
    "            \"George Washington\",\n",
    "            \"Thomas Jefferson[APP Note: Secretary of State.]\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'name': 'Herbert Hoover',\n",
    "        'input': json.dumps([\n",
    "            \"HERBERT HOOVER\",\n",
    "            \"The White House,July 30, 1932.\"\n",
    "        ])\n",
    "    },\n",
    "])\n",
    "model_pool.put(model)\n",
    "\n",
    "pandas.DataFrame(map(process_response, masked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b06014",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'data/executive_orders/raw/'\n",
    "target_dir = 'data/executive_orders/cleaned/'\n",
    "log_path = 'data/executive_orders/cleaned_log.csv'\n",
    "\n",
    "def process_eo(eo_path):\n",
    "    # block until a model becomes available\n",
    "    model = model_pool.get()\n",
    "\n",
    "    result_row = {\n",
    "        'path': eo_path\n",
    "    }\n",
    "    try:\n",
    "        with open(source_dir + eo_path) as source_file:\n",
    "            eo = json.load(source_file)\n",
    "\n",
    "            # clean the byline by replacing \\u2010 with -\n",
    "            eo['president_byline'] = eo['president_byline'].replace('\\u2010', '-')\n",
    "\n",
    "            # content is an array of strings, flatmap strings with new lines into seperate strings\n",
    "            flattened_content = []\n",
    "            for s in eo['content']:\n",
    "                flattened_content.extend(s.splitlines())\n",
    "            eo[\"content\"] = flattened_content\n",
    "\n",
    "            # starting from the end, pick lines with less than 20 words up to the last 5 lines\n",
    "            signature_lines = []\n",
    "            for i in range(1, min(6, len(eo['content']))):\n",
    "                cur_line = eo['content'][-i]\n",
    "                if len(cur_line.split()) < 20:\n",
    "                    signature_lines.append(cur_line)\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # mask if there are lines to mask\n",
    "            if len(signature_lines) > 0:\n",
    "                # try to mask, use unmaked if it fails\n",
    "                try:\n",
    "                    # reverse the signature lines\n",
    "                    signature_lines.reverse()\n",
    "\n",
    "                    # mask the signature lines\n",
    "                    masked_response = process_response(\n",
    "                        make_pipeline(model).invoke({\n",
    "                            'input': json.dumps(signature_lines)\n",
    "                        })\n",
    "                    )\n",
    "\n",
    "                    result_row = result_row | masked_response.copy()\n",
    "                    result_row.pop('masked', None)\n",
    "\n",
    "                    masked_lines = [] if masked_response.get('masked') is None else masked_response.get('masked')\n",
    "\n",
    "                    # skip if the LLM had an obvious wrong solution\n",
    "                    if (len(masked_lines) == len(signature_lines)):\n",
    "                        # replace the signature lines with the masked lines\n",
    "                        eo['content'] = eo['content'][0:-len(signature_lines)] + masked_lines\n",
    "                except Exception as e:\n",
    "                    result_row['error'] = str(e)\n",
    "\n",
    "            # write the cleaned eo to the target directory\n",
    "            with open(target_dir + eo_path, 'w') as target_file:\n",
    "                json.dump(eo, target_file, indent=4)\n",
    "        \n",
    "    finally:\n",
    "        model_pool.put(model)\n",
    "\n",
    "    return result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the raw EOs do some cleanup\n",
    "eo_paths = os.listdir(source_dir)\n",
    "eo_paths.sort()\n",
    "\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=len(model_pool)) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_eo, path) for path in eo_paths\n",
    "    ]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        results.append(future.result())\n",
    "        \n",
    "pandas.DataFrame(results).to_csv(log_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
